# üîç Code Walkthrough - VoiceBot

This guide provides a detailed walkthrough of the VoiceBot codebase, explaining how each component works and how they interact.

## üìã Table of Contents

- [Architecture Overview](#architecture-overview)
- [Backend Code Walkthrough](#backend-code-walkthrough)
- [Frontend Code Walkthrough](#frontend-code-walkthrough)
- [Data Flow](#data-flow)
- [Key Algorithms](#key-algorithms)
- [Service Interactions](#service-interactions)
- [Error Handling](#error-handling)
- [Performance Optimizations](#performance-optimizations)

## üèóÔ∏è Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Frontend (React)                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  App.js ‚Üí useChat.js ‚Üí API Calls ‚Üí Backend                     ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Voice Recording (useAudioRecorder.js)                     ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Text-to-Speech (useTextToSpeech.js)                      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Session Management (localStorage)                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Backend (Express)                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  app.js ‚Üí Routes ‚Üí Services ‚Üí External APIs                    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ chat-rag.js (RAG Pipeline)                               ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ news.js (News Management)                                ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ redisService.js (Session Storage)                        ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ pineconeService.js (Vector Search)                       ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ geminiService.js (LLM)                                   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ pineconeEmbeddingsService.js (Embeddings)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    External Services                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Redis (Sessions) ‚îÇ Pinecone (Vectors) ‚îÇ Gemini (LLM) ‚îÇ OpenAI ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üîß Backend Code Walkthrough

### **1. Entry Point: `src/app.js`**

```javascript
const express = require('express');
const { initializeServices } = require('./services');

const app = express();

// Middleware setup
app.use(cors());
app.use(express.json());
app.use(helmet());
app.use(morgan('combined'));

// Initialize all services
initializeServices().then(() => {
  console.log('‚úÖ All services initialized');
}).catch(error => {
  console.error('‚ùå Service initialization failed:', error);
  process.exit(1);
});

// Routes
app.use('/api/chat', require('./routes/chat-rag'));
app.use('/api/news', require('./routes/news'));
app.use('/api/health', require('./routes/health'));
```

**Key Points:**
- **Service Initialization**: All external services (Redis, Pinecone, Gemini) are initialized before starting the server
- **Middleware Stack**: Security, logging, and parsing middleware are configured
- **Route Mounting**: API routes are mounted with `/api` prefix
- **Error Handling**: Global error handling middleware catches and formats errors

### **2. Service Orchestrator: `src/services/index.js`**

```javascript
async function initializeServices() {
  try {
    // Initialize Redis for session storage
    await redisService.initialize();
    services.redis = redisService;
    
    // Initialize Pinecone for vector search
    await pineconeService.initialize();
    services.pinecone = pineconeService;
    
    // Initialize Gemini for LLM
    await geminiService.initialize();
    services.gemini = geminiService;
    
    // Initialize OpenAI for embeddings
    await pineconeEmbeddingsService.initialize();
    services.pineconeEmbeddings = pineconeEmbeddingsService;
    
    // Initialize News service
    await newsService.initialize();
    services.news = newsService;
    
    return services;
  } catch (error) {
    console.error('‚ùå Failed to initialize services:', error);
    throw error;
  }
}
```

**Key Points:**
- **Dependency Management**: Services are initialized in the correct order
- **Error Propagation**: If any service fails, the entire initialization fails
- **Service Registry**: All services are stored in a central object for easy access

### **3. RAG Chat Route: `src/routes/chat-rag.js`**

```javascript
router.post('/', [
  body('message').notEmpty().withMessage('Message is required'),
  body('sessionId').optional().custom((value) => {
    if (value === null || value === undefined) return true;
    return /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i.test(value);
  }).withMessage('Session ID must be a valid UUID or null'),
  body('stream').optional().isBoolean().withMessage('Stream must be a boolean')
], validateRequest, async (req, res) => {
  try {
    const { message, sessionId, stream = false } = req.body;
    
    // 1. Generate or get session ID
    const currentSessionId = sessionId || uuidv4();
    
    // 2. Generate embedding for user query
    const embedding = await pineconeEmbeddingsService.generateEmbedding(message);
    
    // 3. Search Pinecone for relevant articles
    const searchResults = await pineconeService.query(embedding, {
      topK: 5,
      includeMetadata: true
    });
    
    // 4. Build context from search results
    const context = buildContext(searchResults);
    
    // 5. Get chat history for context
    const chatHistory = await redisService.getChatHistory(currentSessionId);
    
    // 6. Generate response using Gemini
    const response = await geminiService.generateResponse(message, context, chatHistory);
    
    // 7. Store messages in session
    await redisService.addMessageToSession(currentSessionId, message, response.message);
    
    // 8. Return response
    res.json({
      success: true,
      data: {
        sessionId: currentSessionId,
        message: response.message,
        timestamp: new Date().toISOString(),
        metadata: {
          hasContext: context.length > 0,
          articles: searchResults.matches?.map(match => ({
            title: match.metadata?.title || 'Unknown',
            score: match.score
          })) || []
        }
      }
    });
  } catch (error) {
    console.error('Chat error:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});
```

**Key Points:**
- **Input Validation**: Uses express-validator for request validation
- **RAG Pipeline**: Implements the complete RAG flow
- **Session Management**: Handles session creation and retrieval
- **Error Handling**: Comprehensive error handling with proper HTTP status codes

### **4. Redis Service: `src/services/redisService.js`**

```javascript
const redis = require('redis');
const config = require('../config');

let client = null;
let sessionStore = null;

async function initialize() {
  try {
    // Create Redis client
    client = redis.createClient({
      url: config.redis.url
    });
    
    // Connect to Redis
    await client.connect();
    console.log('‚úÖ Redis connected');
    
    // Create session store
    sessionStore = new RedisStore({
      client: client,
      prefix: 'voicebot:session:'
    });
    
    return { client, sessionStore };
  } catch (error) {
    console.error('‚ùå Redis connection failed:', error);
    throw error;
  }
}

async function addMessageToSession(sessionId, userMessage, botMessage) {
  try {
    const sessionKey = `voicebot:session:${sessionId}`;
    
    // Add user message
    await client.lPush(`${sessionKey}:messages`, JSON.stringify({
      id: uuidv4(),
      text: userMessage,
      sender: 'user',
      timestamp: new Date().toISOString()
    }));
    
    // Add bot message
    await client.lPush(`${sessionKey}:messages`, JSON.stringify({
      id: uuidv4(),
      text: botMessage,
      sender: 'assistant',
      timestamp: new Date().toISOString()
    }));
    
    // Set expiration (24 hours)
    await client.expire(sessionKey, 86400);
    
  } catch (error) {
    console.error('Error adding message to session:', error);
    throw error;
  }
}
```

**Key Points:**
- **Connection Management**: Handles Redis connection and reconnection
- **Session Storage**: Uses Redis lists to store chat messages
- **Expiration**: Sessions expire after 24 hours
- **Error Handling**: Graceful error handling for Redis operations

### **5. Pinecone Service: `src/services/pineconeService.js`**

```javascript
const { Pinecone } = require('@pinecone-database/pinecone');
const config = require('../config');

let pinecone = null;
let index = null;

async function initialize() {
  try {
    // Initialize Pinecone client
    pinecone = new Pinecone({
      apiKey: config.pinecone.apiKey
    });
    
    // Get or create index
    const indexName = config.pinecone.indexName;
    const indexes = await pinecone.listIndexes();
    
    if (!indexes.indexes?.find(idx => idx.name === indexName)) {
      console.log(`Pinecone index '${indexName}' not found. Skipping creation for demo purposes.`);
    }
    
    index = pinecone.index(indexName);
    console.log(`Pinecone index '${indexName}' is ready`);
    
    return index;
  } catch (error) {
    console.error('Failed to initialize Pinecone:', error);
    throw error;
  }
}

async function query(embedding, options = {}) {
  try {
    const queryRequest = {
      vector: embedding,
      topK: options.topK || 5,
      includeMetadata: options.includeMetadata || true,
      includeValues: false
    };
    
    const response = await index.query(queryRequest);
    return response;
  } catch (error) {
    console.error('Pinecone query error:', error);
    throw error;
  }
}
```

**Key Points:**
- **Client Initialization**: Uses Pinecone's official Node.js client
- **Index Management**: Handles index existence checking
- **Query Interface**: Provides a clean interface for vector queries
- **Error Handling**: Comprehensive error handling for Pinecone operations

### **6. Gemini Service: `src/services/geminiService.js`**

```javascript
const { GoogleGenerativeAI } = require('@google/generative-ai');
const config = require('../config');

let genAI = null;
let model = null;

async function initialize() {
  try {
    genAI = new GoogleGenerativeAI(config.gemini.apiKey);
    model = genAI.getGenerativeModel({ 
      model: config.gemini.model,
      generationConfig: {
        maxOutputTokens: config.gemini.maxTokens,
        temperature: config.gemini.temperature
      }
    });
    
    console.log('‚úÖ Gemini service initialized');
    return { genAI, model };
  } catch (error) {
    console.error('‚ùå Gemini initialization failed:', error);
    throw error;
  }
}

async function generateResponse(userMessage, context, chatHistory = []) {
  try {
    // Build system prompt
    const systemPrompt = `You are an AI assistant that helps users with questions about current news and events. 
    Use the provided context to answer questions accurately. If the context doesn't contain relevant information, 
    say so and provide a general response based on your knowledge.`;
    
    // Build context string
    const contextString = context.length > 0 
      ? `\n\nContext from recent news articles:\n${context.join('\n\n')}`
      : '';
    
    // Build chat history string
    const historyString = chatHistory.length > 0
      ? `\n\nPrevious conversation:\n${chatHistory.map(msg => `${msg.sender}: ${msg.text}`).join('\n')}`
      : '';
    
    // Combine all parts
    const fullPrompt = `${systemPrompt}${contextString}${historyString}\n\nUser: ${userMessage}\n\nAssistant:`;
    
    // Generate response
    const result = await model.generateContent(fullPrompt);
    const response = await result.response;
    const text = response.text();
    
    return {
      message: text,
      usage: {
        promptTokens: fullPrompt.length,
        completionTokens: text.length
      }
    };
  } catch (error) {
    console.error('Gemini generation error:', error);
    throw error;
  }
}
```

**Key Points:**
- **Model Configuration**: Configures Gemini with specific parameters
- **Prompt Engineering**: Builds comprehensive prompts with context and history
- **Response Generation**: Handles the actual LLM generation
- **Error Handling**: Graceful error handling for API failures

## üé® Frontend Code Walkthrough

### **1. Main Component: `src/App.js`**

```javascript
const App = () => {
  // State management
  const [messages, setMessages] = useState([]);
  const [isMuted, setIsMuted] = useState(false);
  const [isTyping, setIsTyping] = useState(false);
  const [inputText, setInputText] = useState('');
  const [isStreaming, setIsStreaming] = useState(false);
  const [streamingText, setStreamingText] = useState('');
  
  // Custom hooks
  const { 
    sendMessage, 
    sendStreamingMessage,
    sessionId,
    chatHistory,
    isLoading, 
    error: chatError 
  } = useChat();
  
  const { 
    isRecording, 
    startRecording, 
    stopRecording, 
    audioBlob, 
    error: audioError,
    clearAudio 
  } = useAudioRecorder();
  
  const { speak, stopSpeaking } = useTextToSpeech();
  
  // Update messages when chatHistory changes
  useEffect(() => {
    if (chatHistory && chatHistory.length > 0) {
      const formattedMessages = chatHistory.map(msg => ({
        id: msg.id,
        text: msg.text,
        sender: msg.sender,
        timestamp: new Date(msg.timestamp),
        isVoice: false
      }));
      setMessages(formattedMessages);
    } else if (!sessionId) {
      // Show welcome message when no session exists
      setMessages([
        {
          id: 'welcome',
          text: `Hello! ${getTimeGreeting()}! I'm your AI assistant powered by news and current events. How can I help you today?`,
          sender: 'bot',
          timestamp: new Date(),
          isVoice: false
        }
      ]);
    }
  }, [chatHistory, sessionId]);
  
  // Handle sending messages
  const handleSendMessage = async () => {
    if (!inputText.trim() || isProcessing) return;
    
    const messageText = inputText.trim();
    setInputText('');
    
    try {
      setIsTyping(true);
      setIsStreaming(true);
      setStreamingText('');
      
      // Use streaming for better UX
      await sendStreamingMessage(
        messageText,
        // onChunk
        (chunk) => {
          setStreamingText(prev => prev + chunk);
        },
        // onComplete
        (completedSessionId) => {
          setStreamingText('');
          setIsStreaming(false);
          setIsTyping(false);
          
          // Speak the response if not muted
          if (!isMuted && streamingText) {
            speak(streamingText);
          }
        },
        // onError
        (error) => {
          console.error('Streaming error:', error);
          setIsStreaming(false);
          setIsTyping(false);
          setStreamingText('');
        }
      );
    } catch (error) {
      console.error('Error sending message:', error);
      setIsStreaming(false);
      setIsTyping(false);
      setStreamingText('');
    }
  };
  
  return (
    <div className="min-h-screen bg-gradient-to-br from-purple-50 to-blue-50">
      {/* Chat interface JSX */}
    </div>
  );
};
```

**Key Points:**
- **State Management**: Manages UI state and user interactions
- **Custom Hooks**: Uses specialized hooks for different functionalities
- **Effect Hooks**: Handles side effects like updating messages
- **Event Handlers**: Manages user interactions and API calls

### **2. Chat Hook: `src/hooks/useChat.js`**

```javascript
const useChat = () => {
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState(null);
  const [sessionId, setSessionId] = useState(() => {
    // Load session ID from localStorage on initialization
    return localStorage.getItem('chatSessionId') || null;
  });
  const [chatHistory, setChatHistory] = useState([]);
  
  // Save session ID to localStorage whenever it changes
  useEffect(() => {
    if (sessionId) {
      localStorage.setItem('chatSessionId', sessionId);
    } else {
      localStorage.removeItem('chatSessionId');
    }
  }, [sessionId]);
  
  // Load chat history when session ID is available
  useEffect(() => {
    if (sessionId) {
      loadChatHistory();
    }
  }, [sessionId]);
  
  const loadChatHistory = useCallback(async () => {
    if (!sessionId) return;
    
    try {
      const response = await fetch(`${API_BASE_URL}/chat/history/${sessionId}`);
      
      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }
      
      const data = await response.json();
      
      if (data.success) {
        setChatHistory(data.data.messages || []);
      }
    } catch (err) {
      console.error('Failed to load chat history:', err);
    }
  }, [sessionId]);
  
  const sendMessage = useCallback(async (message, options = {}) => {
    setIsLoading(true);
    setError(null);
    
    try {
      const response = await fetch(`${API_BASE_URL}/chat`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          message,
          sessionId: sessionId || options.sessionId,
          stream: options.stream || false
        }),
      });
      
      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }
      
      const data = await response.json();
      
      if (data.success) {
        // Set session ID if not already set
        if (!sessionId && data.data.sessionId) {
          setSessionId(data.data.sessionId);
        }
        
        // Reload chat history to get the latest messages
        if (data.data.sessionId) {
          await loadChatHistory();
        }
        
        return {
          response: data.data.message,
          sessionId: data.data.sessionId,
          contextFound: data.data.metadata?.hasContext || false,
          contextChunks: data.data.metadata?.articles || [],
          timestamp: data.data.timestamp
        };
      } else {
        throw new Error(data.error || 'Failed to send message');
      }
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'Failed to send message';
      setError(errorMessage);
      throw err;
    } finally {
      setIsLoading(false);
    }
  }, [sessionId, loadChatHistory]);
  
  return {
    sendMessage,
    sendStreamingMessage,
    getChatHistory,
    clearChatHistory,
    resetSession,
    sessionId,
    chatHistory,
    isLoading,
    error
  };
};
```

**Key Points:**
- **Session Persistence**: Uses localStorage to persist sessions
- **State Management**: Manages chat state and loading states
- **API Communication**: Handles all backend API calls
- **Error Handling**: Comprehensive error handling and user feedback

### **3. Audio Recorder Hook: `src/hooks/useAudioRecorder.js`**

```javascript
const useAudioRecorder = () => {
  const [isRecording, setIsRecording] = useState(false);
  const [audioBlob, setAudioBlob] = useState(null);
  const [error, setError] = useState(null);
  const [mediaRecorder, setMediaRecorder] = useState(null);
  const [audioChunks, setAudioChunks] = useState([]);
  
  const startRecording = useCallback(async () => {
    try {
      setError(null);
      
      // Get user media
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100
        } 
      });
      
      // Create MediaRecorder
      const recorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      
      // Handle data available
      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          setAudioChunks(prev => [...prev, event.data]);
        }
      };
      
      // Handle recording stop
      recorder.onstop = () => {
        const blob = new Blob(audioChunks, { type: 'audio/webm;codecs=opus' });
        setAudioBlob(blob);
        setAudioChunks([]);
        
        // Stop all tracks
        stream.getTracks().forEach(track => track.stop());
      };
      
      // Start recording
      recorder.start(100); // Collect data every 100ms
      setMediaRecorder(recorder);
      setIsRecording(true);
      
    } catch (err) {
      console.error('Error starting recording:', err);
      setError(err.message);
    }
  }, [audioChunks]);
  
  const stopRecording = useCallback(() => {
    if (mediaRecorder && isRecording) {
      mediaRecorder.stop();
      setIsRecording(false);
    }
  }, [mediaRecorder, isRecording]);
  
  const clearAudio = useCallback(() => {
    setAudioBlob(null);
    setAudioChunks([]);
    setError(null);
  }, []);
  
  return {
    isRecording,
    startRecording,
    stopRecording,
    audioBlob,
    error,
    clearAudio
  };
};
```

**Key Points:**
- **Web Audio API**: Uses MediaRecorder for audio recording
- **Stream Management**: Handles media stream creation and cleanup
- **Blob Handling**: Manages audio data as blobs
- **Error Handling**: Comprehensive error handling for audio operations

## üîÑ Data Flow

### **1. User Message Flow**

```
User Input ‚Üí Frontend ‚Üí API Call ‚Üí Backend ‚Üí RAG Pipeline ‚Üí Response ‚Üí Frontend
```

**Detailed Steps:**
1. User types message in frontend
2. Frontend calls `sendMessage` hook
3. Hook makes POST request to `/api/chat`
4. Backend validates request and extracts message
5. Backend generates embedding for message
6. Backend searches Pinecone for relevant articles
7. Backend builds context from search results
8. Backend calls Gemini with context and message
9. Backend stores conversation in Redis
10. Backend returns response to frontend
11. Frontend updates UI with response

### **2. Session Management Flow**

```
New User ‚Üí Session Creation ‚Üí Redis Storage ‚Üí Frontend localStorage ‚Üí Persistent Chat
```

**Detailed Steps:**
1. User sends first message
2. Backend generates new UUID for session
3. Backend stores session in Redis with expiration
4. Backend returns session ID to frontend
5. Frontend stores session ID in localStorage
6. Frontend loads chat history for session
7. Subsequent messages use existing session

### **3. RAG Pipeline Flow**

```
User Query ‚Üí Embedding ‚Üí Vector Search ‚Üí Context Retrieval ‚Üí LLM Generation ‚Üí Response
```

**Detailed Steps:**
1. User query is received
2. OpenAI generates embedding for query
3. Pinecone searches for similar vectors
4. Relevant articles are retrieved
5. Context is built from articles
6. Gemini generates response with context
7. Response is returned to user

## üßÆ Key Algorithms

### **1. Embedding Generation**
```javascript
async function generateEmbedding(text) {
  const response = await openai.embeddings.create({
    model: "text-embedding-ada-002",
    input: text
  });
  return response.data[0].embedding;
}
```

### **2. Vector Search**
```javascript
async function searchVectors(embedding, topK = 5) {
  const queryRequest = {
    vector: embedding,
    topK: topK,
    includeMetadata: true,
    includeValues: false
  };
  return await index.query(queryRequest);
}
```

### **3. Context Building**
```javascript
function buildContext(searchResults) {
  if (!searchResults.matches || searchResults.matches.length === 0) {
    return [];
  }
  
  return searchResults.matches.map(match => {
    const metadata = match.metadata || {};
    return `Title: ${metadata.title || 'Unknown'}\nContent: ${metadata.content || 'No content available'}`;
  });
}
```

### **4. Prompt Engineering**
```javascript
function buildPrompt(userMessage, context, chatHistory) {
  const systemPrompt = `You are an AI assistant that helps users with questions about current news and events.`;
  const contextString = context.length > 0 ? `\n\nContext:\n${context.join('\n\n')}` : '';
  const historyString = chatHistory.length > 0 ? `\n\nPrevious conversation:\n${chatHistory.map(msg => `${msg.sender}: ${msg.text}`).join('\n')}` : '';
  
  return `${systemPrompt}${contextString}${historyString}\n\nUser: ${userMessage}\n\nAssistant:`;
}
```

## üîó Service Interactions

### **1. Redis Service**
- **Purpose**: Session storage and chat history
- **Operations**: Store, retrieve, delete sessions
- **Data Structure**: Redis lists for message storage
- **Expiration**: 24-hour TTL for sessions

### **2. Pinecone Service**
- **Purpose**: Vector similarity search
- **Operations**: Query vectors, retrieve metadata
- **Data Structure**: Vector embeddings with metadata
- **Index**: Pre-populated with news articles

### **3. Gemini Service**
- **Purpose**: Large language model generation
- **Operations**: Generate responses with context
- **Configuration**: Temperature, max tokens, model selection
- **Prompting**: System prompts with context injection

### **4. OpenAI Service**
- **Purpose**: Embedding generation
- **Operations**: Convert text to vectors
- **Model**: text-embedding-ada-002
- **Usage**: Query embedding for similarity search

## ‚ùå Error Handling

### **1. Backend Error Handling**
```javascript
// Global error handler
app.use((error, req, res, next) => {
  console.error('Global error:', error);
  res.status(500).json({
    success: false,
    error: process.env.NODE_ENV === 'production' 
      ? 'Internal server error' 
      : error.message
  });
});

// Service error handling
try {
  const result = await service.operation();
  return result;
} catch (error) {
  console.error('Service error:', error);
  throw new Error(`Service operation failed: ${error.message}`);
}
```

### **2. Frontend Error Handling**
```javascript
// API error handling
try {
  const response = await fetch(url, options);
  if (!response.ok) {
    throw new Error(`HTTP error! status: ${response.status}`);
  }
  const data = await response.json();
  return data;
} catch (error) {
  console.error('API error:', error);
  setError(error.message);
  throw error;
}
```

### **3. Service Resilience**
- **Retry Logic**: Automatic retries for transient failures
- **Circuit Breaker**: Prevents cascading failures
- **Graceful Degradation**: Fallback responses when services fail
- **Monitoring**: Comprehensive logging and error tracking

## ‚ö° Performance Optimizations

### **1. Caching**
- **Redis Caching**: Session data and chat history
- **Response Caching**: Cached responses for similar queries
- **Static Asset Caching**: Frontend assets cached by CDN

### **2. Database Optimizations**
- **Index Optimization**: Pinecone index configuration
- **Query Optimization**: Efficient vector search queries
- **Connection Pooling**: Redis connection pooling

### **3. Frontend Optimizations**
- **Code Splitting**: Lazy loading of components
- **Memoization**: React.memo for expensive components
- **Debouncing**: Input debouncing for API calls
- **Streaming**: Real-time response streaming

### **4. API Optimizations**
- **Request Batching**: Batch multiple requests
- **Response Compression**: Gzip compression for responses
- **Rate Limiting**: Prevent API abuse
- **Timeout Handling**: Proper timeout configuration

---

## üéØ Key Takeaways

1. **Modular Architecture**: Clean separation of concerns between frontend and backend
2. **Service-Oriented Design**: Each service has a specific responsibility
3. **Error Handling**: Comprehensive error handling at all levels
4. **Performance**: Optimized for speed and scalability
5. **User Experience**: Smooth interactions with real-time feedback
6. **Maintainability**: Clean, well-documented code structure

**This codebase demonstrates modern full-stack development practices with AI integration! üöÄ**
