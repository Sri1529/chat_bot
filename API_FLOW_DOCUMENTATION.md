# Voice-Enabled Chatbot API Flow Documentation

## ğŸ¯ Overview
This document explains the complete API flow of the voice-enabled chatbot system, from user voice input to AI response generation, including vector search and LLM integration.

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend       â”‚    â”‚   Vector Store  â”‚    â”‚   LLM Service   â”‚
â”‚   (React)       â”‚    â”‚   (FastAPI)     â”‚    â”‚   (AWS S3)      â”‚    â”‚   (OpenAI)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Complete API Flow

### 1. **User Voice Input** ğŸ¤
```
User speaks â†’ Web Speech API â†’ Text Transcription
```

**Frontend Process:**
- User clicks microphone button
- `useVoiceToText` hook activates Web Speech API
- Browser captures audio and converts to text
- Text is stored in `transcript` state

**Code Location:** `frontend/src/hooks/useVoiceToText.ts`
```typescript
const startRecording = useCallback(() => {
  const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
  recognition.onresult = (event) => {
    const transcript = event.results[0][0].transcript;
    setTranscript(transcript);
  };
  recognition.start();
}, []);
```

### 2. **WebSocket Communication** ğŸ”Œ
```
Frontend â†’ WebSocket â†’ Backend
```

**Frontend Process:**
- `useWebSocket` hook sends transcribed text via WebSocket
- Message format: `{ message: string, organisation_id: number, project_id: number, is_voice: boolean }`

**Code Location:** `frontend/src/hooks/useWebSocket.ts`
```typescript
const sendMessage = useCallback((message: string, isVoice: boolean = false) => {
  if (wsRef.current?.readyState === WebSocket.OPEN) {
    wsRef.current.send(JSON.stringify({
      message,
      organisation_id: 1,
      project_id: 1,
      is_voice: isVoice
    }));
  }
}, []);
```

### 3. **Backend WebSocket Handler** ğŸ–¥ï¸
```
WebSocket â†’ FastAPI â†’ Message Processing
```

**Backend Process:**
- WebSocket endpoint receives message at `/ws`
- Message is logged and processed
- Text is sent to chat endpoint for further processing

**Code Location:** `backend/app/main.py`
```python
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    logger.info("WebSocket connected. Total connections: 1")
    
    try:
        while True:
            data = await websocket.receive_text()
            message_data = json.loads(data)
            logger.info(f"Received message: {message_data}")
            
            # Process message and send response back
            response = await process_message(message_data)
            await websocket.send_text(json.dumps(response))
```

### 4. **Vector Store Query** ğŸ”
```
Text â†’ Embeddings â†’ Vector Search â†’ Relevant Chunks
```

**Backend Process:**
- `VectorStoreService` generates embeddings using Amazon Titan
- Queries AWS S3 Vector Store for similar vectors
- Filters by organisation_id and project_id
- Returns top 5 most relevant chunks

**Code Location:** `backend/app/services/vector_store_service.py`
```python
def query_vectors(self, query_vector: List[float], organisation_id: int, project_id: int, limit: int = 5):
    response = self.s3vectors.query_vectors(
        vectorBucketName=settings.AWS_S3_VECTOR_STORE_BUCKET,
        indexName=settings.DOC_INDEX_NAME,
        queryVector={"float32": query_vector},
        returnMetadata=True,
        filter={"$and": [
            {"organisation_id": {"$eq": organisation_id}},
            {"project_id": {"$eq": project_id}}
        ]},
        topK=limit
    )
    return response
```

### 5. **LLM Response Generation** ğŸ¤–
```
Query + Context â†’ OpenAI GPT-3.5 â†’ AI Response
```

**Backend Process:**
- `LLMService` combines user query with relevant chunks
- Sends to OpenAI GPT-3.5-turbo for response generation
- Returns contextual AI response

**Code Location:** `backend/app/services/llm_service.py`
```python
def process_query_with_context(self, query: str, relevant_chunks: List[str]) -> str:
    context = "\n\n".join(relevant_chunks)
    
    response = self.client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "system",
                "content": f"You are a helpful assistant. Use ONLY the following context to answer the user's question. If the context doesn't contain relevant information to answer the question, respond with exactly 'no context found'.\n\nContext:\n{context}"
            },
            {"role": "user", "content": query}
        ],
        max_tokens=500,
        temperature=0.7
    )
    return response.choices[0].message.content
```

### 6. **Response Back to Frontend** ğŸ“¤
```
AI Response â†’ WebSocket â†’ Frontend â†’ Text-to-Speech
```

**Frontend Process:**
- Receives AI response via WebSocket
- Displays response in chat interface
- `useTextToSpeech` hook converts text to speech
- User hears the AI response

**Code Location:** `frontend/src/hooks/useTextToSpeech.ts`
```typescript
const speak = useCallback((text: string) => {
  if (isSpeaking) {
    speechSynthesis.cancel();
  }
  
  const utterance = new SpeechSynthesisUtterance(text);
  utterance.onend = () => setIsSpeaking(false);
  utterance.onerror = () => setIsSpeaking(false);
  
  speechSynthesis.speak(utterance);
  setIsSpeaking(true);
}, [isSpeaking]);
```

## ğŸ“Š Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   USER VOICE    â”‚    â”‚   FRONTEND      â”‚    â”‚   BACKEND       â”‚    â”‚   AWS SERVICES  â”‚
â”‚   INPUT         â”‚    â”‚   (React)       â”‚    â”‚   (FastAPI)     â”‚    â”‚   (S3 + OpenAI) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚                        â”‚                        â”‚
         â”‚ 1. User speaks         â”‚                        â”‚                        â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                        â”‚                        â”‚
         â”‚                        â”‚                        â”‚                        â”‚
         â”‚                        â”‚ 2. Web Speech API      â”‚                        â”‚
         â”‚                        â”‚    converts to text    â”‚                        â”‚
         â”‚                        â”‚                        â”‚                        â”‚
         â”‚                        â”‚ 3. WebSocket send      â”‚                        â”‚
         â”‚                        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                        â”‚
         â”‚                        â”‚                        â”‚                        â”‚
         â”‚                        â”‚                        â”‚ 4. Generate embeddings â”‚
         â”‚                        â”‚                        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
         â”‚                        â”‚                        â”‚                        â”‚
         â”‚                        â”‚                        â”‚ 5. Query vector store â”‚
         â”‚                        â”‚                        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
         â”‚                        â”‚                        â”‚                        â”‚
         â”‚                        â”‚                        â”‚ 6. Get relevant chunksâ”‚
         â”‚                        â”‚                        â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚                        â”‚                        â”‚                        â”‚
         â”‚                        â”‚                        â”‚ 7. Send to LLM         â”‚
         â”‚                        â”‚                        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
         â”‚                        â”‚                        â”‚                        â”‚
         â”‚                        â”‚                        â”‚ 8. Get AI response     â”‚
         â”‚                        â”‚                        â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚                        â”‚                        â”‚                        â”‚
         â”‚                        â”‚ 9. WebSocket response  â”‚                        â”‚
         â”‚                        â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                        â”‚
         â”‚                        â”‚                        â”‚                        â”‚
         â”‚                        â”‚ 10. Display response   â”‚                        â”‚
         â”‚                        â”‚                        â”‚                        â”‚
         â”‚                        â”‚ 11. Text-to-Speech     â”‚                        â”‚
         â”‚                        â”‚    converts to voice   â”‚                        â”‚
         â”‚                        â”‚                        â”‚                        â”‚
         â”‚ 12. User hears responseâ”‚                        â”‚                        â”‚
         â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                        â”‚                        â”‚
```

## ğŸ”„ Step-by-Step Flow

1. **User Voice Input** â†’ Web Speech API converts speech to text
2. **Text Transcription** â†’ Frontend captures transcribed text
3. **WebSocket Send** â†’ Text sent to backend via WebSocket
4. **Generate Embeddings** â†’ Backend creates vector embeddings using Amazon Titan
5. **Query Vector Store** â†’ Search AWS S3 Vector Store for similar content
6. **Get Relevant Chunks** â†’ Retrieve top 5 most relevant text chunks
7. **Send to LLM** â†’ Send query + context to OpenAI GPT-3.5
8. **Get AI Response** â†’ Receive contextual AI response
9. **WebSocket Response** â†’ Send response back to frontend
10. **Display Response** â†’ Show response in chat interface
11. **Text-to-Speech** â†’ Convert response to speech
12. **Voice Output** â†’ User hears the AI response

## ğŸ”§ API Endpoints

### WebSocket Endpoints
- **`/ws`** - Main WebSocket connection for real-time chat

### HTTP Endpoints
- **`/api/v1/health/`** - Health check endpoint
- **`/api/v1/chat/message`** - HTTP chat message endpoint (POST)

## ğŸ—‚ï¸ File Structure

```
chatbot/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useVoiceToText.ts      # Voice-to-text functionality
â”‚   â”‚   â”‚   â”œâ”€â”€ useTextToSpeech.ts     # Text-to-speech functionality
â”‚   â”‚   â”‚   â””â”€â”€ useWebSocket.ts        # WebSocket communication
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ MessageList.tsx        # Chat message display
â”‚   â”‚   â”‚   â””â”€â”€ VoiceRecorder.tsx      # Microphone button
â”‚   â”‚   â””â”€â”€ App.tsx                    # Main application component
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ vector_store_service.py # AWS S3 Vector Store integration
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_service.py         # OpenAI LLM integration
â”‚   â”‚   â”‚   â””â”€â”€ voice_service.py       # Voice processing service
â”‚   â”‚   â”œâ”€â”€ api/v1/endpoints/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py                # Chat endpoints
â”‚   â”‚   â”‚   â””â”€â”€ health.py              # Health check endpoint
â”‚   â”‚   â””â”€â”€ main.py                    # FastAPI application
â””â”€â”€ docker-compose.yml                 # Docker orchestration
```

## ğŸ”‘ Environment Variables

### Backend (.env)
```bash
# AWS Configuration
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_REGION=us-east-1
AWS_S3_VECTOR_STORE_BUCKET=your_bucket_name
DOC_INDEX_NAME=vault-ai-index

# OpenAI Configuration
OPENAI_API_KEY=your_openai_key

# Vector Store Configuration
EMBEDDING_MODEL_ID=amazon.titan-embed-text-v2:0
VECTOR_DIMENSION=512
```

## ğŸš€ How to Use

1. **Start Backend:**
   ```bash
   cd backend
   source venv/bin/activate
   uvicorn app.main:app --host 0.0.0.0 --port 5001 --reload
   ```

2. **Start Frontend:**
   ```bash
   cd frontend
   PORT=5000 npm start
   ```

3. **Access Application:**
   - Frontend: http://localhost:5000
   - Backend: http://localhost:5001

## ğŸ” Key Features

- **Voice Input**: Real-time speech-to-text conversion
- **Vector Search**: Semantic search through your data
- **AI Responses**: Context-aware responses using OpenAI
- **Voice Output**: Text-to-speech for responses
- **Real-time**: WebSocket-based communication
- **Multi-tenant**: Organisation and project-based filtering

## ğŸ› ï¸ Technologies Used

- **Frontend**: React, TypeScript, Tailwind CSS, Web Speech API
- **Backend**: Python, FastAPI, WebSockets
- **Vector Store**: AWS S3 Vector Store, Amazon Titan Embeddings
- **LLM**: OpenAI GPT-3.5-turbo
- **Deployment**: Docker, Docker Compose

## ğŸ“ Message Format

### WebSocket Message (Frontend â†’ Backend)
```json
{
  "message": "Hello, how are you?",
  "organisation_id": 1,
  "project_id": 1,
  "is_voice": true
}
```

### WebSocket Response (Backend â†’ Frontend)
```json
{
  "response": "I'm doing well, thank you for asking!",
  "is_voice": true,
  "timestamp": 1694356789.123
}
```

This documentation provides a complete understanding of how the voice-enabled chatbot processes user input through the entire system pipeline.
